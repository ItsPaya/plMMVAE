{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torch import optim, nn, utils, Tensor\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using torch 1.12.1+cu102\n",
      "X tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# tensor board to represent models!\n",
    "# check\n",
    "\n",
    "print(\"using torch\", torch.__version__)\n",
    "\n",
    "torch.manual_seed(47)\n",
    "x = torch.arange(6)\n",
    "x = x.view(2,3)\n",
    "print(\"X\", x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def draw_circle(radius, center_x=0.5, center_y=0.5, size=28):\n",
    "    # draw a circle using coordinates for the center and the radius\n",
    "    circle = plt.Circle((center_x,center_y), radius, color='k', fill=False)\n",
    "    fig,ax = plt.subplots(figsize=(1,1))\n",
    "    ax.add_patch(circle)\n",
    "    ax.axis('off')\n",
    "    buf = fig.canvas.print_to_buffer()\n",
    "    plt.close()\n",
    "    # converts matplotlib figure into pil image, make it grayscale and resize it\n",
    "    return np.array(Image.frombuffer('RGBA', buf[1], buf[0]).convert('L').resize((int(size), int(size))))\n",
    "\n",
    "def gen_circles(n, size=28):\n",
    "    # generates random coordinates around (0.5, 0.5) as center points\n",
    "    center_x = np.random.uniform(0.0,0.03, size=n).reshape(-1,1)+.5\n",
    "    center_y = np.random.uniform(0.0,0.03, size=n).reshape(-1,1)+.5\n",
    "    # generates random radius sizes between 0.03 and 0.47\n",
    "    radius = np.random.uniform(0.03,0.47, size=n).reshape(-1,1)\n",
    "    sizes = np.ones((n,1))*size\n",
    "\n",
    "    coords = np.concatenate([radius, center_x, center_y, sizes], axis=1)\n",
    "    # generates circles using draw_circle function\n",
    "    circles = np.apply_along_axis(func1d=lambda v: draw_circle(*v), axis=1, arr=coords)\n",
    "    return circles, radius\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "# generates 1'000 circles\n",
    "circles, radius = gen_circles(1000)\n",
    "\n",
    "circles_ds = utils.data.TensorDataset(torch.as_tensor(circles).unsqueeze(1).float()/255, torch.as_tensor(radius))\n",
    "circles_dl = utils.data.DataLoader(circles_ds, batch_size=32, shuffle=True, drop_last=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def set_seed(self, seed=42):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_shape, z_size, base_model):\n",
    "        super().__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.z_size = z_size\n",
    "        self.base_model = base_model\n",
    "\n",
    "        # appends the \"lin_latent\" linear layer to map form \"output_size\"\n",
    "        # given by the base model to desired size of the representation ( z_size)\n",
    "        output_size = self._get_output_size()\n",
    "        self.lin_latent = nn.Linear(output_size, z_size)\n",
    "\n",
    "    def _get_output_size(self):\n",
    "        # builds a dummy batch containing one dummy tensor\n",
    "        # fully of zeros with the same shape as the inputs\n",
    "        device = next(self.base_model.parameters()).device.type\n",
    "        dummy = torch.zeros(1, *self.input_shape, device=device)\n",
    "        # sends the dummy batch through the base model to get\n",
    "        # the output size produced by it\n",
    "        size = self.base_model(dummy).size(1)\n",
    "        return size\n",
    "\n",
    "    def forward(self, x):\n",
    "        # forwards the input through the base model and then the \"lin_latent\" layer\n",
    "        # to get the representation (z)\n",
    "        base_out = self.base_model(x)\n",
    "        out = self.lin_latent(base_out)\n",
    "        return out\n",
    "\n",
    "set_seed(13)\n",
    "\n",
    "# defined out representation (z) as a vector of size one\n",
    "z_size = 1\n",
    "# our images are 1@28x28\n",
    "input_shape = (1,28,28) # (C,H,W)\n",
    "\n",
    "base_model = nn.Sequential(\n",
    "    # (C,H,W) -> C*H*W\n",
    "    nn.Flatten(),\n",
    "    # C*H*W -> 2048\n",
    "    nn.Linear(np.prod(input_shape), 2048),\n",
    "    nn.LeakyReLU(),\n",
    "    # 2048 -> 2048\n",
    "    nn.Linear(2048,2048),\n",
    "    nn.LeakyReLU()\n",
    ")\n",
    "\n",
    "encoder = Encoder(input_shape, z_size, base_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.1209]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, _ = circles_ds[7]\n",
    "z = encoder(x)\n",
    "z"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "decoder = nn.Sequential(\n",
    "    # z_size -> 2048\n",
    "    nn.Linear(z_size, 2048),\n",
    "    nn.LeakyReLU(),\n",
    "    # 2048 -> 2048\n",
    "    nn.Linear(2048, 2048),\n",
    "    nn.LeakyReLU(),\n",
    "    # 2048 -> C*H*W\n",
    "    nn.Linear(2048, np.prod(input_shape)),\n",
    "    # C*H*W -> (C, H, W)\n",
    "    nn.Unflatten(1, input_shape)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[[ 1.9079e-01, -4.3900e-02, -4.9170e-02,  5.2142e-02, -8.0119e-02,\n            -1.6324e-01,  3.8319e-02,  6.2965e-02, -3.7442e-02, -3.6085e-02,\n             2.2930e-02, -1.2089e-01,  2.0558e-01,  1.3671e-01,  1.4607e-03,\n             1.1066e-02, -1.3429e-01, -3.7842e-02,  6.1736e-02, -3.0216e-02,\n            -7.4171e-02, -1.6376e-02, -6.4663e-02, -1.5638e-01, -9.6260e-02,\n             5.3312e-02,  6.6354e-02, -2.6916e-02],\n           [ 1.8874e-01,  9.7503e-02, -1.3948e-01, -1.2955e-01, -1.2210e-02,\n             5.6815e-02, -7.5753e-02,  5.3484e-02,  6.4153e-02, -1.6740e-01,\n            -5.0190e-02,  6.2855e-02,  9.7707e-02, -2.2777e-02, -1.1442e-01,\n             1.6079e-01, -1.4634e-01,  2.0068e-01, -2.7668e-02,  6.3487e-02,\n            -9.6758e-02,  3.0803e-02, -7.0600e-02,  1.1162e-01,  8.6569e-02,\n            -1.5205e-02,  1.9754e-01,  1.1691e-01],\n           [-7.3312e-02,  9.0082e-02, -4.4267e-02,  1.1471e-01,  6.9005e-02,\n             1.5236e-03, -4.2527e-02,  1.4255e-01, -4.4042e-02,  6.3819e-02,\n            -8.4292e-02, -1.4427e-01, -1.0588e-01,  1.9977e-01,  7.7565e-03,\n            -1.4625e-01,  1.7524e-01,  1.7738e-01,  1.5645e-01, -2.1747e-01,\n             6.4080e-02, -9.2407e-02,  1.2629e-01,  4.6970e-02, -4.5570e-02,\n             7.9688e-02, -2.1363e-01,  2.9808e-02],\n           [ 1.3239e-01,  1.4318e-02,  9.5405e-02, -2.2642e-01, -1.9234e-01,\n            -8.1496e-02, -4.8343e-02, -1.8153e-01, -1.7878e-01,  1.0769e-02,\n            -1.2494e-01,  7.7014e-02, -2.1142e-02, -4.1185e-03,  1.2169e-01,\n            -5.6018e-03, -2.6061e-02, -2.2577e-01,  2.9144e-02,  1.7661e-01,\n             7.1272e-02,  1.7548e-01,  2.8129e-02, -8.8633e-02,  1.0452e-01,\n            -7.5592e-02, -1.0330e-02, -1.2894e-01],\n           [-3.6175e-02,  1.4285e-01,  4.5606e-02, -8.2213e-02, -8.0643e-02,\n            -5.8190e-02,  5.7487e-02,  6.6390e-02,  1.6105e-01,  3.0311e-01,\n            -4.2740e-03, -2.1283e-01,  3.0256e-03,  7.3140e-02,  9.6907e-02,\n            -6.7109e-02,  5.7137e-02, -2.1398e-02,  1.2691e-01, -2.9634e-02,\n             1.4555e-02,  1.0292e-01, -5.6350e-02,  1.8181e-03,  1.1265e-02,\n             1.0917e-01,  3.8503e-02, -5.5837e-02],\n           [ 5.2709e-02,  5.9560e-02, -5.1096e-02,  1.6033e-01, -5.3603e-03,\n            -1.9936e-02, -6.4266e-02,  4.0338e-03, -4.8038e-02, -1.3491e-01,\n            -2.2655e-01, -1.6381e-02, -6.5734e-02,  2.4132e-02,  1.1650e-01,\n            -2.8200e-02,  6.7357e-03,  1.4424e-01, -7.6789e-02, -1.2859e-01,\n             1.3307e-01,  1.9751e-01, -1.2719e-01, -6.8411e-02, -4.9764e-02,\n             6.6571e-02,  1.1602e-02, -3.5575e-02],\n           [-8.3470e-02,  6.2510e-02, -5.0334e-03,  6.2090e-02,  1.1036e-01,\n            -5.4733e-03,  1.0506e-01, -2.5115e-02, -1.1901e-03,  1.0367e-01,\n             3.4260e-02, -1.5983e-01,  1.4022e-01,  1.6859e-01,  3.2468e-02,\n             1.9934e-01,  8.1105e-02,  1.5346e-02,  5.0475e-02,  2.3097e-01,\n             1.1854e-01,  2.4383e-02, -8.6751e-02, -8.3177e-02, -3.7389e-02,\n             7.2396e-02,  4.1882e-02, -1.1091e-01],\n           [ 3.1028e-02, -3.9857e-03,  3.4163e-02, -1.9548e-01, -1.2043e-01,\n            -4.3684e-02, -1.2961e-01, -6.1097e-02, -1.4778e-02, -4.7092e-02,\n             1.0835e-01, -4.0080e-03,  3.6721e-02, -1.7156e-01,  3.9559e-02,\n             1.1675e-01,  1.0704e-03,  9.3677e-02,  1.6970e-01,  9.1701e-02,\n             7.6041e-02,  1.1238e-01, -8.1656e-02, -1.6955e-01, -1.4713e-01,\n            -5.0936e-02, -4.0298e-02, -1.5382e-01],\n           [-1.4083e-01, -2.7302e-01,  4.4792e-02,  2.7869e-02, -8.1398e-02,\n             3.3563e-02, -3.6415e-02, -5.6773e-02, -2.8709e-02,  1.5262e-01,\n             1.9070e-02, -1.8026e-02, -9.8355e-02, -5.9920e-02, -1.5127e-02,\n            -1.0465e-01,  1.9231e-02,  2.6793e-02, -9.3692e-02, -9.6902e-02,\n            -1.9051e-02,  1.1318e-01,  3.0637e-02,  1.5574e-02,  1.5724e-01,\n             3.1492e-02, -1.4979e-02, -3.2647e-02],\n           [ 2.0283e-01, -6.1705e-02, -3.8050e-02,  1.9809e-02, -3.1082e-02,\n            -3.0309e-02, -5.1703e-02, -1.4745e-01, -6.8283e-02,  4.1344e-02,\n            -3.9841e-02,  1.0617e-01, -7.7280e-02,  1.6024e-01, -2.3414e-02,\n            -3.7018e-03,  2.8419e-02,  4.6259e-02, -9.1629e-02,  5.8694e-02,\n            -3.8974e-02,  1.8875e-02, -1.4879e-01, -6.6794e-02, -1.2453e-01,\n            -1.5017e-02,  6.1985e-02, -1.6195e-01],\n           [-4.0127e-02, -5.4723e-02,  2.0498e-02, -1.0191e-02,  3.3329e-02,\n            -1.1681e-01,  1.3395e-01,  2.8045e-02,  6.5280e-02,  5.8197e-02,\n            -8.8265e-02,  9.5805e-02,  2.0792e-02, -1.6245e-01,  7.4805e-02,\n            -1.4505e-01,  1.6747e-01, -2.0788e-01, -6.4071e-02,  3.5464e-02,\n            -1.0121e-01,  1.0144e-01,  1.6357e-01, -1.8122e-03, -1.1847e-02,\n             2.4049e-01, -9.4793e-02,  2.3748e-01],\n           [ 2.8316e-02, -1.0385e-02,  1.4707e-01, -1.2564e-01,  7.7421e-02,\n             1.2372e-01,  1.0141e-01,  1.6038e-02, -1.9445e-01,  1.2901e-01,\n             1.1352e-01, -8.5296e-02, -1.1946e-01,  1.5142e-01,  1.4371e-02,\n            -8.1590e-02,  7.0791e-02,  3.4378e-02,  5.1303e-02,  3.1741e-02,\n            -1.5130e-01, -1.5549e-02,  1.5242e-01,  1.2468e-01, -1.9453e-01,\n            -3.2025e-02,  3.8546e-02, -1.4266e-02],\n           [ 1.0443e-03, -2.5030e-01, -1.6817e-02, -8.7387e-02,  9.8546e-02,\n            -2.1816e-02,  9.7024e-02, -8.6624e-02, -3.9576e-03, -7.4825e-02,\n            -9.8882e-02,  2.3828e-01, -2.5858e-02, -6.9627e-02, -4.1895e-02,\n             1.8798e-01,  2.6024e-02,  2.3761e-03, -2.0961e-01, -1.6544e-01,\n             1.5001e-01,  3.2879e-02, -4.7173e-02,  5.1330e-02, -6.8451e-02,\n            -1.3578e-01,  1.9232e-01,  1.4095e-01],\n           [ 1.7399e-02,  9.4299e-02,  5.1881e-02, -1.8462e-01,  9.9171e-02,\n            -1.0139e-01,  1.4946e-01,  7.0240e-02, -5.4906e-02,  7.4256e-02,\n            -1.0001e-01, -1.3835e-01, -8.8885e-02, -3.4873e-02,  7.6121e-02,\n            -1.6557e-02,  2.8654e-02,  3.1901e-02,  1.3658e-01, -2.4831e-02,\n             9.6723e-02, -6.7969e-02,  1.6831e-03, -1.3638e-01,  2.9050e-02,\n             1.6166e-01,  5.6500e-02,  1.2940e-01],\n           [ 3.8112e-02, -9.2519e-02, -3.2853e-03,  5.7534e-03,  4.1605e-03,\n             1.2173e-02, -1.3176e-02, -5.4871e-02,  3.0539e-02, -1.7041e-01,\n             1.1253e-02, -6.9670e-02, -1.6437e-01, -8.5709e-02,  9.6036e-02,\n             1.0574e-01,  1.2689e-01,  3.9872e-02,  7.9335e-03, -8.1893e-02,\n            -8.8046e-02, -6.8677e-02,  2.9659e-02, -3.3759e-02,  7.8553e-02,\n            -3.3709e-02,  7.6034e-02, -1.9016e-02],\n           [-1.6651e-02,  5.7128e-02,  6.7234e-02, -5.1183e-02,  1.5547e-01,\n            -7.5864e-02,  1.6600e-02, -1.0607e-01, -5.1661e-02, -4.6499e-02,\n            -1.9357e-01, -7.1232e-02,  1.3268e-01,  1.7344e-01, -1.6895e-01,\n            -2.1734e-02,  2.1688e-02, -1.8922e-01, -3.9262e-02, -4.6287e-02,\n             5.1127e-02,  1.2940e-01,  5.6841e-02,  4.8147e-03, -8.0629e-03,\n             5.5161e-02, -1.0631e-01,  1.6104e-02],\n           [-4.3611e-02, -3.3030e-02, -1.2267e-02, -1.1373e-01,  5.1175e-02,\n             1.0146e-01, -8.6729e-02, -2.8264e-02, -1.4270e-01, -1.3206e-01,\n            -7.8748e-02, -8.0216e-02,  3.3299e-03,  1.5390e-01,  1.3152e-01,\n            -5.4470e-02, -6.1082e-02,  9.9820e-03,  1.6672e-02, -1.9279e-02,\n             1.8126e-02, -8.2174e-02,  5.9327e-02,  1.1550e-01,  1.0617e-01,\n            -4.4917e-02, -1.8522e-02, -1.4423e-02],\n           [-2.3343e-02, -4.5935e-02,  2.5590e-02,  7.4355e-02, -1.3717e-02,\n            -1.3692e-01,  1.0452e-01, -4.4021e-02,  4.1331e-02, -5.4528e-02,\n            -1.8238e-02,  2.4965e-02, -2.3323e-01, -8.3915e-02,  4.3719e-02,\n            -6.1408e-02, -1.4109e-02,  1.1034e-01,  2.4522e-01, -1.9923e-02,\n            -2.8638e-02,  2.8130e-01,  6.1974e-02,  3.2529e-02, -1.1198e-01,\n            -5.1031e-02, -1.1702e-01, -1.7054e-01],\n           [ 6.8059e-02, -1.8582e-01,  6.7678e-02, -5.7972e-02,  1.6102e-05,\n             1.1760e-01, -1.1538e-01, -8.8099e-02,  3.7294e-02,  9.2221e-02,\n            -1.9951e-02,  1.4669e-02,  4.4360e-02,  1.8074e-01,  4.0267e-02,\n            -7.6020e-02, -1.9685e-02,  6.5778e-02, -8.2714e-03, -4.8466e-02,\n             1.2239e-01, -3.4879e-02, -8.8673e-02, -9.8539e-02, -4.1404e-02,\n             3.3682e-02, -2.8446e-02, -9.6935e-02],\n           [-9.2022e-02, -4.6900e-02, -1.2283e-01, -3.4136e-02, -1.2322e-02,\n            -2.0296e-02, -5.9181e-03,  1.8984e-01,  5.1903e-02, -5.0289e-02,\n             2.5736e-02,  3.4985e-02,  8.1324e-03,  1.7809e-01, -2.9438e-01,\n            -9.9281e-02, -8.2007e-02,  9.8012e-03,  7.9573e-02,  3.3273e-02,\n             3.0407e-02,  4.6310e-02, -9.8136e-02, -5.2822e-02,  1.9834e-01,\n             3.1424e-02, -5.0940e-02, -6.7326e-02],\n           [-2.6838e-02,  9.9456e-02,  6.2650e-02,  1.4759e-01, -6.4575e-02,\n            -6.1139e-02, -5.9339e-03, -9.1012e-02, -3.3184e-02,  5.9196e-03,\n            -1.9240e-01, -1.0201e-01, -9.3665e-02, -1.0552e-01,  2.4925e-01,\n            -2.9895e-01, -6.1178e-02, -1.3329e-01,  1.7635e-01,  1.0591e-01,\n             4.8642e-02,  4.1704e-02, -9.9700e-02,  9.8024e-03, -1.0057e-01,\n            -1.3683e-02, -1.8332e-01, -2.6579e-02],\n           [ 1.8783e-01, -8.0937e-02, -1.0608e-01, -8.8277e-02,  1.4993e-02,\n            -1.9171e-01,  7.5505e-02, -1.2535e-01,  1.4611e-01, -7.2075e-02,\n             9.6701e-02,  1.4883e-03, -1.6249e-01, -1.3729e-01, -4.0112e-02,\n             9.6686e-02, -1.1872e-01,  5.9813e-02, -2.0608e-01, -1.4734e-02,\n             2.8171e-02,  3.0755e-03,  1.5188e-01, -1.2407e-01, -2.2186e-02,\n             1.6235e-01,  1.0546e-01, -2.6897e-02],\n           [ 1.5839e-02,  2.1223e-02,  5.7086e-02, -8.5850e-03, -2.3191e-02,\n            -1.7922e-01, -4.8345e-02, -1.9446e-02, -6.3801e-02,  1.8813e-02,\n             7.2606e-03, -3.2520e-02, -6.7380e-02,  1.2899e-02, -1.1156e-01,\n            -1.1024e-02, -3.0672e-02,  3.5529e-02, -6.3607e-02, -3.4413e-02,\n             1.0340e-01,  2.7990e-02,  4.9956e-03,  1.7666e-01, -4.2988e-02,\n             1.1072e-01,  3.6767e-02,  5.1066e-03],\n           [ 8.5983e-02, -1.2444e-01,  2.0306e-01, -1.1263e-01,  1.3163e-01,\n            -1.3153e-02,  6.8176e-02,  6.8968e-02, -4.9623e-02, -3.6764e-02,\n             1.1465e-02, -3.3643e-02, -1.3114e-01,  5.8302e-02,  5.4208e-02,\n            -4.5142e-02,  1.0005e-01,  8.3354e-03, -1.0874e-01,  1.8789e-02,\n             2.7832e-01,  1.5549e-02,  5.1989e-02, -3.5839e-02, -3.6681e-02,\n            -7.2586e-02, -1.3513e-01, -1.4281e-01],\n           [ 2.1048e-01, -1.2105e-01, -4.7375e-02,  1.0856e-01,  2.4025e-01,\n             1.4577e-01,  3.7638e-02, -5.7412e-02,  8.7973e-02, -5.0064e-02,\n             5.2866e-05, -1.9702e-02, -4.8341e-02,  1.8881e-01, -6.6422e-03,\n             1.4488e-01,  1.1330e-01,  7.2832e-02, -9.8568e-02,  4.1775e-02,\n            -4.8157e-02,  1.1571e-01,  1.1027e-01,  4.4301e-02, -1.3606e-01,\n            -6.2045e-02, -4.3796e-02,  1.1102e-01],\n           [-6.7072e-02,  3.3816e-03, -8.1244e-02,  5.1976e-02,  2.1043e-01,\n             5.5551e-02,  9.8623e-02, -1.5066e-01, -1.5751e-01,  2.6280e-01,\n             1.1145e-01, -2.6457e-02, -5.1827e-02,  3.2250e-02, -8.6951e-02,\n            -3.6659e-03,  1.8162e-02, -3.2856e-02, -9.7966e-02, -1.6849e-01,\n             1.3899e-01, -4.0634e-02, -4.1636e-02,  2.9081e-03,  1.1897e-01,\n             1.7839e-02, -8.0604e-02, -1.0983e-01],\n           [-2.2135e-01,  1.9544e-02, -2.6946e-03, -1.3309e-01,  1.8477e-01,\n            -1.3968e-01,  1.9612e-01, -1.0488e-01, -5.5342e-02, -7.5556e-02,\n             6.4676e-02,  7.6878e-02,  8.1507e-02, -1.2121e-01, -5.2191e-03,\n            -8.1300e-02,  8.2085e-02, -2.6678e-02,  6.1831e-02, -7.9537e-02,\n            -5.0615e-02,  1.6095e-01, -1.3630e-01, -4.5869e-02, -1.3313e-01,\n            -1.2590e-01,  8.6214e-04,  1.0599e-01],\n           [ 8.8277e-02, -6.6287e-03,  1.1928e-01, -5.3350e-02,  5.1256e-02,\n            -1.9218e-01, -1.1696e-02,  9.2000e-02, -2.0761e-02,  1.3698e-01,\n             1.1031e-01, -1.6434e-01,  2.4815e-03,  7.6435e-02,  9.1158e-02,\n             8.1965e-02,  8.3374e-02, -9.2417e-02,  6.1851e-02, -1.2176e-01,\n            -1.5925e-02,  4.5633e-02, -2.2794e-02, -3.2587e-02,  4.3843e-02,\n             1.3819e-01, -1.5780e-01,  1.9806e-02]]]], grad_fn=<ViewBackward0>),\n torch.Size([1, 1, 28, 28]))"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tilde = decoder(z)\n",
    "x_tilde, x_tilde.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.enc = encoder\n",
    "        self.dec = decoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        # when encoder met decoder\n",
    "        enc_out = self.enc(x)\n",
    "        return self.dec(enc_out)\n",
    "\n",
    "model_ae = AutoEncoder(encoder, decoder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Loss >> 0.1388\n",
      "Epoch 002 | Loss >> 0.0062\n",
      "Epoch 003 | Loss >> 0.0049\n",
      "Epoch 004 | Loss >> 0.0048\n",
      "Epoch 005 | Loss >> 0.0048\n",
      "Epoch 006 | Loss >> 0.0048\n",
      "Epoch 007 | Loss >> 0.0048\n",
      "Epoch 008 | Loss >> 0.0048\n",
      "Epoch 009 | Loss >> 0.0047\n",
      "Epoch 010 | Loss >> 0.0045\n"
     ]
    }
   ],
   "source": [
    "set_seed(13)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_ae.to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optim = optim.Adam(model_ae.parameters(), 0.0003)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    batch_losses = []\n",
    "    for i, (x,_) in enumerate(circles_dl):\n",
    "        model_ae.train()\n",
    "        x = x.to(device)\n",
    "\n",
    "        # step1 compute model's predicted output - forward pass\n",
    "        yhat = model_ae(x)\n",
    "        # step2 compute loss\n",
    "        loss = loss_fn(yhat, x)\n",
    "        # step3 compute gradients\n",
    "        loss.backward()\n",
    "        # step4 update param using gradients and learning rate\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "        batch_losses.append(np.array([loss.data.item()]))\n",
    "\n",
    "    # avg over batches\n",
    "    train_losses.append(np.array(batch_losses).mean(axis=0))\n",
    "\n",
    "    print(f'Epoch {epoch:03d} | Loss >> {train_losses[-1][0]:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def set_seed(self, seed=42):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "class EncoderVar(nn.Module):\n",
    "    def __init__(self, input_shape, z_size, base_model):\n",
    "        super().__init__()\n",
    "        self.z_size = z_size\n",
    "        self.input_shape = input_shape\n",
    "        self.base_model = base_model\n",
    "        output_size = self.get_output_size()\n",
    "        self.lin_mu = nn.Linear(output_size, z_size)\n",
    "        self.lin_var = nn.Linear(output_size, z_size)\n",
    "\n",
    "    def get_output_size(self):\n",
    "        device = next(self.base_model.parameters()).device.type\n",
    "        size = self.base_model(torch.zeros(1, *self.input_shape, device=device)).size(1)\n",
    "        return size\n",
    "\n",
    "    def kl_loss(self):\n",
    "        kl_loss = -0.5*(1 + self.log_var - self.mu**2 - torch.exp(self.log_var))\n",
    "        return kl_loss\n",
    "\n",
    "    def forward(self, x):\n",
    "        base_out = self.base_model(x)\n",
    "\n",
    "        # now encoder produces means (mu) using the lin_mu output layer\n",
    "        # and log variances (log_var) using hte lin_var output layer\n",
    "        # compute the standard deviation (std) from the log variance\n",
    "        self.mu = self.lin_mu(base_out)\n",
    "        self.log_var = self.lin_var(base_out)\n",
    "        std = torch.exp(self.log_var/2)\n",
    "\n",
    "        # internal random input (epsilon)\n",
    "        eps = torch.randn_like(self.mu)\n",
    "        # and z vector\n",
    "        z = self.mu + eps * std\n",
    "\n",
    "        return z"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "set_seed(13)\n",
    "# defined out representation (z) as a vector of size one\n",
    "z_size = 1\n",
    "# our images are 1@28x28\n",
    "input_shape = (1,28,28) # (C,H,W)\n",
    "base_model = nn.Sequential(\n",
    "    # (C,H,W) -> C*H*W\n",
    "    nn.Flatten(),\n",
    "    # C*H*W -> 2048\n",
    "    nn.Linear(np.prod(input_shape), 2048),\n",
    "    nn.LeakyReLU(),\n",
    "    # 2048 -> 2048\n",
    "    nn.Linear(2048,2048),\n",
    "    nn.LeakyReLU()\n",
    ")\n",
    "\n",
    "\n",
    "encoder_var = EncoderVar(input_shape, z_size, base_model)\n",
    "\n",
    "decoder_var = nn.Sequential(\n",
    "    # z_size -> 2048\n",
    "    nn.Linear(z_size, 2048),\n",
    "    nn.LeakyReLU(),\n",
    "    # 2048 -> 2048\n",
    "    nn.Linear(2048, 2048),\n",
    "    nn.LeakyReLU(),\n",
    "    # 2048 -> C*H*W\n",
    "    nn.Linear(2048, np.prod(input_shape)),\n",
    "    # C*H*W -> (C, H, W)\n",
    "    nn.Unflatten(1, input_shape)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class LitVAutoEncoder(pl.LightningModule):\n",
    "    def __init__(self, encoderV, decoderV):\n",
    "        super().__init__()\n",
    "        self.encoderV = encoderV\n",
    "        self.decoderV = decoderV\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoderV(x)\n",
    "        x_hat = self.decoderV(z)\n",
    "        lossV = nn.functional.mse_loss(x_hat, x)\n",
    "        return lossV\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name     | Type       | Params\n",
      "----------------------------------------\n",
      "0 | encoderV | EncoderVar | 5.8 M \n",
      "1 | decoderV | Sequential | 5.8 M \n",
      "----------------------------------------\n",
      "11.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.6 M    Total params\n",
      "46.460    Total estimated model params size (MB)\n",
      "/home/payam/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/payam/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1892: PossibleUserWarning: The number of training batches (31) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "785264f791564a21a7f80fc61a5c176a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16928/3632869705.py:12: UserWarning: Using a target size (torch.Size([32, 784])) that is different to the input size (torch.Size([32, 1, 28, 28])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  lossV = nn.functional.mse_loss(x_hat, x)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (28) must match the size of tensor b (784) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [10], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m model_vae \u001B[38;5;241m=\u001B[39m LitVAutoEncoder(encoder_var, decoder_var)\n\u001B[1;32m      3\u001B[0m trainer \u001B[38;5;241m=\u001B[39m pl\u001B[38;5;241m.\u001B[39mTrainer(limit_train_batches\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, max_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_vae\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcircles_dl\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:696\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    677\u001B[0m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    678\u001B[0m \u001B[38;5;124;03mRuns the full optimization routine.\u001B[39;00m\n\u001B[1;32m    679\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    693\u001B[0m \u001B[38;5;124;03m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001B[39;00m\n\u001B[1;32m    694\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    695\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m model\n\u001B[0;32m--> 696\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    697\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[1;32m    698\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:650\u001B[0m, in \u001B[0;36mTrainer._call_and_handle_interrupt\u001B[0;34m(self, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m    648\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    649\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 650\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    651\u001B[0m \u001B[38;5;66;03m# TODO(awaelchli): Unify both exceptions below, where `KeyboardError` doesn't re-raise\u001B[39;00m\n\u001B[1;32m    652\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exception:\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:735\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    731\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m ckpt_path \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresume_from_checkpoint\n\u001B[1;32m    732\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__set_ckpt_path(\n\u001B[1;32m    733\u001B[0m     ckpt_path, model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    734\u001B[0m )\n\u001B[0;32m--> 735\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    737\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[1;32m    738\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1166\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n\u001B[1;32m   1162\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39mrestore_training_state()\n\u001B[1;32m   1164\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39mresume_end()\n\u001B[0;32m-> 1166\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1168\u001B[0m log\u001B[38;5;241m.\u001B[39mdetail(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1169\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_teardown()\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1252\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1250\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredicting:\n\u001B[1;32m   1251\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_predict()\n\u001B[0;32m-> 1252\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1283\u001B[0m, in \u001B[0;36mTrainer._run_train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1280\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit_loop\u001B[38;5;241m.\u001B[39mtrainer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\n\u001B[1;32m   1282\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mset_detect_anomaly(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_detect_anomaly):\n\u001B[0;32m-> 1283\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:200\u001B[0m, in \u001B[0;36mLoop.run\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    199\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_start(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 200\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madvance\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    201\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_end()\n\u001B[1;32m    202\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_restarting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:271\u001B[0m, in \u001B[0;36mFitLoop.advance\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    267\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_fetcher\u001B[38;5;241m.\u001B[39msetup(\n\u001B[1;32m    268\u001B[0m     dataloader, batch_to_device\u001B[38;5;241m=\u001B[39mpartial(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39m_call_strategy_hook, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch_to_device\u001B[39m\u001B[38;5;124m\"\u001B[39m, dataloader_idx\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m    269\u001B[0m )\n\u001B[1;32m    270\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_training_epoch\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 271\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepoch_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_fetcher\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:200\u001B[0m, in \u001B[0;36mLoop.run\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    199\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_start(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 200\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madvance\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    201\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_end()\n\u001B[1;32m    202\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_restarting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:203\u001B[0m, in \u001B[0;36mTrainingEpochLoop.advance\u001B[0;34m(self, data_fetcher)\u001B[0m\n\u001B[1;32m    200\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_progress\u001B[38;5;241m.\u001B[39mincrement_started()\n\u001B[1;32m    202\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_training_batch\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 203\u001B[0m         batch_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    205\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_progress\u001B[38;5;241m.\u001B[39mincrement_processed()\n\u001B[1;32m    207\u001B[0m \u001B[38;5;66;03m# update non-plateau LR schedulers\u001B[39;00m\n\u001B[1;32m    208\u001B[0m \u001B[38;5;66;03m# update epoch-interval ones only when we are at the end of training epoch\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:200\u001B[0m, in \u001B[0;36mLoop.run\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    199\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_start(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 200\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madvance\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    201\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_end()\n\u001B[1;32m    202\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_restarting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py:87\u001B[0m, in \u001B[0;36mTrainingBatchLoop.advance\u001B[0;34m(self, kwargs)\u001B[0m\n\u001B[1;32m     83\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mlightning_module\u001B[38;5;241m.\u001B[39mautomatic_optimization:\n\u001B[1;32m     84\u001B[0m     optimizers \u001B[38;5;241m=\u001B[39m _get_active_optimizers(\n\u001B[1;32m     85\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39moptimizers, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39moptimizer_frequencies, kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch_idx\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     86\u001B[0m     )\n\u001B[0;32m---> 87\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43moptimizers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     88\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     89\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmanual_loop\u001B[38;5;241m.\u001B[39mrun(kwargs)\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:200\u001B[0m, in \u001B[0;36mLoop.run\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    199\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_start(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 200\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madvance\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    201\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_end()\n\u001B[1;32m    202\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_restarting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:201\u001B[0m, in \u001B[0;36mOptimizerLoop.advance\u001B[0;34m(self, optimizers, kwargs)\u001B[0m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21madvance\u001B[39m(\u001B[38;5;28mself\u001B[39m, optimizers: List[Tuple[\u001B[38;5;28mint\u001B[39m, Optimizer]], kwargs: OrderedDict) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# type: ignore[override]\u001B[39;00m\n\u001B[1;32m    199\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_kwargs(kwargs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer_idx, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_hiddens)\n\u001B[0;32m--> 201\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_optimization\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_optimizers\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptim_progress\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer_position\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    202\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m result\u001B[38;5;241m.\u001B[39mloss \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    203\u001B[0m         \u001B[38;5;66;03m# automatic optimization assumes a loss needs to be returned for extras to be considered as the batch\u001B[39;00m\n\u001B[1;32m    204\u001B[0m         \u001B[38;5;66;03m# would be skipped otherwise\u001B[39;00m\n\u001B[1;32m    205\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_outputs[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer_idx] \u001B[38;5;241m=\u001B[39m result\u001B[38;5;241m.\u001B[39masdict()\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:248\u001B[0m, in \u001B[0;36mOptimizerLoop._run_optimization\u001B[0;34m(self, kwargs, optimizer)\u001B[0m\n\u001B[1;32m    240\u001B[0m         closure()\n\u001B[1;32m    242\u001B[0m \u001B[38;5;66;03m# ------------------------------\u001B[39;00m\n\u001B[1;32m    243\u001B[0m \u001B[38;5;66;03m# BACKWARD PASS\u001B[39;00m\n\u001B[1;32m    244\u001B[0m \u001B[38;5;66;03m# ------------------------------\u001B[39;00m\n\u001B[1;32m    245\u001B[0m \u001B[38;5;66;03m# gradient update with accumulated gradients\u001B[39;00m\n\u001B[1;32m    246\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    247\u001B[0m     \u001B[38;5;66;03m# the `batch_idx` is optional with inter-batch parallelism\u001B[39;00m\n\u001B[0;32m--> 248\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_optimizer_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopt_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbatch_idx\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclosure\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    250\u001B[0m result \u001B[38;5;241m=\u001B[39m closure\u001B[38;5;241m.\u001B[39mconsume_result()\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result\u001B[38;5;241m.\u001B[39mloss \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    253\u001B[0m     \u001B[38;5;66;03m# if no result, user decided to skip optimization\u001B[39;00m\n\u001B[1;32m    254\u001B[0m     \u001B[38;5;66;03m# otherwise update running loss + reset accumulated loss\u001B[39;00m\n\u001B[1;32m    255\u001B[0m     \u001B[38;5;66;03m# TODO: find proper way to handle updating running loss\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:358\u001B[0m, in \u001B[0;36mOptimizerLoop._optimizer_step\u001B[0;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001B[0m\n\u001B[1;32m    355\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptim_progress\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mstep\u001B[38;5;241m.\u001B[39mincrement_ready()\n\u001B[1;32m    357\u001B[0m \u001B[38;5;66;03m# model hook\u001B[39;00m\n\u001B[0;32m--> 358\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_lightning_module_hook\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    359\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moptimizer_step\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    360\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcurrent_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    361\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_idx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    362\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    363\u001B[0m \u001B[43m    \u001B[49m\u001B[43mopt_idx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    364\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_step_and_backward_closure\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    365\u001B[0m \u001B[43m    \u001B[49m\u001B[43mon_tpu\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maccelerator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mTPUAccelerator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    366\u001B[0m \u001B[43m    \u001B[49m\u001B[43musing_native_amp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mamp_backend\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mAMPType\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mNATIVE\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    367\u001B[0m \u001B[43m    \u001B[49m\u001B[43musing_lbfgs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_lbfgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    368\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    370\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m should_accumulate:\n\u001B[1;32m    371\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptim_progress\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mstep\u001B[38;5;241m.\u001B[39mincrement_completed()\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1550\u001B[0m, in \u001B[0;36mTrainer._call_lightning_module_hook\u001B[0;34m(self, hook_name, pl_module, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1547\u001B[0m pl_module\u001B[38;5;241m.\u001B[39m_current_fx_name \u001B[38;5;241m=\u001B[39m hook_name\n\u001B[1;32m   1549\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[LightningModule]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpl_module\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 1550\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;66;03m# restore current_fx when nested context\u001B[39;00m\n\u001B[1;32m   1553\u001B[0m pl_module\u001B[38;5;241m.\u001B[39m_current_fx_name \u001B[38;5;241m=\u001B[39m prev_fx_name\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1705\u001B[0m, in \u001B[0;36mLightningModule.optimizer_step\u001B[0;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001B[0m\n\u001B[1;32m   1623\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moptimizer_step\u001B[39m(\n\u001B[1;32m   1624\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1625\u001B[0m     epoch: \u001B[38;5;28mint\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1632\u001B[0m     using_lbfgs: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m   1633\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1634\u001B[0m     \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1635\u001B[0m \u001B[38;5;124;03m    Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001B[39;00m\n\u001B[1;32m   1636\u001B[0m \u001B[38;5;124;03m    each optimizer.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1703\u001B[0m \n\u001B[1;32m   1704\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1705\u001B[0m     \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclosure\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer_closure\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py:168\u001B[0m, in \u001B[0;36mLightningOptimizer.step\u001B[0;34m(self, closure, **kwargs)\u001B[0m\n\u001B[1;32m    165\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MisconfigurationException(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWhen `optimizer.step(closure)` is called, the closure should be callable\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    167\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_strategy \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 168\u001B[0m step_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_strategy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer_step\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_optimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_optimizer_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclosure\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_on_after_step()\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m step_output\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:216\u001B[0m, in \u001B[0;36mStrategy.optimizer_step\u001B[0;34m(self, optimizer, opt_idx, closure, model, **kwargs)\u001B[0m\n\u001B[1;32m    206\u001B[0m \u001B[38;5;124;03m\"\"\"Performs the actual optimizer step.\u001B[39;00m\n\u001B[1;32m    207\u001B[0m \n\u001B[1;32m    208\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;124;03m    **kwargs: Any extra arguments to ``optimizer.step``\u001B[39;00m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    215\u001B[0m model \u001B[38;5;241m=\u001B[39m model \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module\n\u001B[0;32m--> 216\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprecision_plugin\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopt_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclosure\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py:153\u001B[0m, in \u001B[0;36mPrecisionPlugin.optimizer_step\u001B[0;34m(self, model, optimizer, optimizer_idx, closure, **kwargs)\u001B[0m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(model, pl\u001B[38;5;241m.\u001B[39mLightningModule):\n\u001B[1;32m    152\u001B[0m     closure \u001B[38;5;241m=\u001B[39m partial(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wrap_closure, model, optimizer, optimizer_idx, closure)\n\u001B[0;32m--> 153\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclosure\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclosure\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/torch/optim/optimizer.py:113\u001B[0m, in \u001B[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    111\u001B[0m profile_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOptimizer.step#\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.step\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(obj\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[1;32m    112\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mrecord_function(profile_name):\n\u001B[0;32m--> 113\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001B[0m, in \u001B[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclone():\n\u001B[0;32m---> 27\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/torch/optim/adam.py:118\u001B[0m, in \u001B[0;36mAdam.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m closure \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    117\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39menable_grad():\n\u001B[0;32m--> 118\u001B[0m         loss \u001B[38;5;241m=\u001B[39m \u001B[43mclosure\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    120\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m group \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparam_groups:\n\u001B[1;32m    121\u001B[0m     params_with_grad \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py:138\u001B[0m, in \u001B[0;36mPrecisionPlugin._wrap_closure\u001B[0;34m(self, model, optimizer, optimizer_idx, closure)\u001B[0m\n\u001B[1;32m    125\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_wrap_closure\u001B[39m(\n\u001B[1;32m    126\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    127\u001B[0m     model: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpl.LightningModule\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    130\u001B[0m     closure: Callable[[], Any],\n\u001B[1;32m    131\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    132\u001B[0m     \u001B[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the\u001B[39;00m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;124;03m    ``on_before_optimizer_step`` hook is called.\u001B[39;00m\n\u001B[1;32m    134\u001B[0m \n\u001B[1;32m    135\u001B[0m \u001B[38;5;124;03m    The closure (generally) runs ``backward`` so this allows inspecting gradients in this hook. This structure is\u001B[39;00m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;124;03m    consistent with the ``PrecisionPlugin`` subclasses that cannot pass ``optimizer.step(closure)`` directly.\u001B[39;00m\n\u001B[1;32m    137\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 138\u001B[0m     closure_result \u001B[38;5;241m=\u001B[39m \u001B[43mclosure\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    139\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_after_closure(model, optimizer, optimizer_idx)\n\u001B[1;32m    140\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m closure_result\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:146\u001B[0m, in \u001B[0;36mClosure.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optional[Tensor]:\n\u001B[0;32m--> 146\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclosure\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    147\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result\u001B[38;5;241m.\u001B[39mloss\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:132\u001B[0m, in \u001B[0;36mClosure.closure\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mclosure\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ClosureResult:\n\u001B[0;32m--> 132\u001B[0m     step_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_step_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m step_output\u001B[38;5;241m.\u001B[39mclosure_loss \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    135\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwarning_cache\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:407\u001B[0m, in \u001B[0;36mOptimizerLoop._training_step\u001B[0;34m(self, kwargs)\u001B[0m\n\u001B[1;32m    398\u001B[0m \u001B[38;5;124;03m\"\"\"Performs the actual train step with the tied hooks.\u001B[39;00m\n\u001B[1;32m    399\u001B[0m \n\u001B[1;32m    400\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    404\u001B[0m \u001B[38;5;124;03m    A ``ClosureResult`` containing the training step output.\u001B[39;00m\n\u001B[1;32m    405\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    406\u001B[0m \u001B[38;5;66;03m# manually capture logged metrics\u001B[39;00m\n\u001B[0;32m--> 407\u001B[0m training_step_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_strategy_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtraining_step\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    408\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mpost_training_step()\n\u001B[1;32m    410\u001B[0m model_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39m_call_lightning_module_hook(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtraining_step_end\u001B[39m\u001B[38;5;124m\"\u001B[39m, training_step_output)\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1704\u001B[0m, in \u001B[0;36mTrainer._call_strategy_hook\u001B[0;34m(self, hook_name, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1701\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m   1703\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[Strategy]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 1704\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1706\u001B[0m \u001B[38;5;66;03m# restore current_fx when nested context\u001B[39;00m\n\u001B[1;32m   1707\u001B[0m pl_module\u001B[38;5;241m.\u001B[39m_current_fx_name \u001B[38;5;241m=\u001B[39m prev_fx_name\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:358\u001B[0m, in \u001B[0;36mStrategy.training_step\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    356\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprecision_plugin\u001B[38;5;241m.\u001B[39mtrain_step_context():\n\u001B[1;32m    357\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, TrainingStep)\n\u001B[0;32m--> 358\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn [9], line 12\u001B[0m, in \u001B[0;36mLitVAutoEncoder.training_step\u001B[0;34m(self, batch, batch_idx)\u001B[0m\n\u001B[1;32m     10\u001B[0m z \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoderV(x)\n\u001B[1;32m     11\u001B[0m x_hat \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoderV(z)\n\u001B[0;32m---> 12\u001B[0m lossV \u001B[38;5;241m=\u001B[39m \u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunctional\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmse_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_hat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m lossV\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/torch/nn/functional.py:3279\u001B[0m, in \u001B[0;36mmse_loss\u001B[0;34m(input, target, size_average, reduce, reduction)\u001B[0m\n\u001B[1;32m   3276\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3277\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[0;32m-> 3279\u001B[0m expanded_input, expanded_target \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbroadcast_tensors\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3280\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_nn\u001B[38;5;241m.\u001B[39mmse_loss(expanded_input, expanded_target, _Reduction\u001B[38;5;241m.\u001B[39mget_enum(reduction))\n",
      "File \u001B[0;32m~/PycharmProject/LightTest/venv/lib/python3.10/site-packages/torch/functional.py:73\u001B[0m, in \u001B[0;36mbroadcast_tensors\u001B[0;34m(*tensors)\u001B[0m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function(tensors):\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(broadcast_tensors, tensors, \u001B[38;5;241m*\u001B[39mtensors)\n\u001B[0;32m---> 73\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbroadcast_tensors\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: The size of tensor a (28) must match the size of tensor b (784) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "model_vae = LitVAutoEncoder(encoder_var, decoder_var)\n",
    "\n",
    "trainer = pl.Trainer(limit_train_batches=100, max_epochs=100)\n",
    "trainer.fit(model=model_vae, train_dataloaders=circles_dl)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 1, 28, 28])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(circles_dl))\n",
    "zs = encoder_var(x)\n",
    "reconstructed = decoder_var(zs)\n",
    "\n",
    "loss_fn_raw = nn.MSELoss(reduction='none')\n",
    "raw_mse = loss_fn_raw(reconstructed, x)\n",
    "raw_mse.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(24936.3203, grad_fn=<SumBackward0>),\n tensor(24936.3203, grad_fn=<MseLossBackward0>))"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_mse.sum(), nn.MSELoss(reduction='sum')(reconstructed, x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(779.2599, grad_fn=<MeanBackward0>)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_over_pixels = raw_mse.sum(dim=[1, 2, 3])\n",
    "sum_over_pixels.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 1])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_kl = encoder_var.kl_loss()\n",
    "raw_kl.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Loss >> 2915.1128/ 2876.9089/ 38.2040\n",
      "Epoch 002 | Loss >> 186.8791/ 145.8311/ 41.0480\n",
      "Epoch 003 | Loss >> 160.9378/ 133.0548/ 27.8830\n",
      "Epoch 004 | Loss >> 143.0788/ 128.7050/ 14.3739\n",
      "Epoch 005 | Loss >> 134.0556/ 128.5861/ 5.4695\n",
      "Epoch 006 | Loss >> 130.6097/ 129.6743/ 0.9354\n",
      "Epoch 007 | Loss >> 127.0032/ 126.0474/ 0.9557\n",
      "Epoch 008 | Loss >> 125.9513/ 125.6287/ 0.3226\n",
      "Epoch 009 | Loss >> 127.9104/ 127.6522/ 0.2581\n",
      "Epoch 010 | Loss >> 127.8795/ 127.5232/ 0.3563\n",
      "Epoch 011 | Loss >> 126.9872/ 126.6768/ 0.3105\n",
      "Epoch 012 | Loss >> 127.4638/ 127.3409/ 0.1230\n",
      "Epoch 013 | Loss >> 127.4611/ 127.1741/ 0.2869\n",
      "Epoch 014 | Loss >> 127.8259/ 127.6131/ 0.2128\n",
      "Epoch 015 | Loss >> 126.3635/ 126.1700/ 0.1935\n",
      "Epoch 016 | Loss >> 131.2211/ 130.9681/ 0.2530\n",
      "Epoch 017 | Loss >> 130.1056/ 129.8042/ 0.3014\n",
      "Epoch 018 | Loss >> 129.5030/ 129.0640/ 0.4390\n",
      "Epoch 019 | Loss >> 129.6932/ 129.3315/ 0.3617\n",
      "Epoch 020 | Loss >> 127.4312/ 127.0978/ 0.3334\n",
      "Epoch 021 | Loss >> 129.0741/ 128.9009/ 0.1733\n",
      "Epoch 022 | Loss >> 129.2332/ 128.9400/ 0.2932\n",
      "Epoch 023 | Loss >> 128.3342/ 127.7197/ 0.6144\n",
      "Epoch 024 | Loss >> 126.7638/ 126.4886/ 0.2753\n",
      "Epoch 025 | Loss >> 129.7884/ 128.9965/ 0.7919\n",
      "Epoch 026 | Loss >> 127.3477/ 127.1407/ 0.2070\n",
      "Epoch 027 | Loss >> 127.8019/ 127.4589/ 0.3429\n",
      "Epoch 028 | Loss >> 128.5384/ 128.3313/ 0.2071\n",
      "Epoch 029 | Loss >> 127.8850/ 127.6147/ 0.2703\n",
      "Epoch 030 | Loss >> 127.8629/ 127.5388/ 0.3241\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_vae.to(device)\n",
    "loss_fn = nn.MSELoss(reduction='none')\n",
    "optim = torch.optim.Adam(model_vae.parameters(), 0.0003)\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "train_losses = []\n",
    "\n",
    "reconstruction_loss_factor = 1\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    batch_losses = []\n",
    "    for i, (x, _) in enumerate(circles_dl):\n",
    "        model_vae.train()\n",
    "        x = x.to(device)\n",
    "\n",
    "        # step1 compute predicted output - forward pass\n",
    "        yhat = model_vae(x)\n",
    "        # step2 compute loss\n",
    "        # reduce (sum) over pixels (dim=[1, 2, 3])\n",
    "        # then reduce (sum) over batch (dim=0)\n",
    "        loss = loss_fn(yhat, x).sum(dim=[1, 2, 3]).sum(dim=0)\n",
    "        # reduce (sum) over z (dim=1)\n",
    "        # then reduce (sum) over batch (dim=0)\n",
    "        kl_loss = model_vae.enc.kl_loss().sum(dim=1).sum(dim=0)\n",
    "        # adding kl loss to original mse loss\n",
    "        total_loss = reconstruction_loss_factor * loss + kl_loss\n",
    "        # step3 compute gradients\n",
    "        total_loss.backward()\n",
    "        # step4 update param using gradients and learning rate\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "        batch_losses.append(np.array([total_loss.data.item(), loss.data.item(), kl_loss.data.item()]))\n",
    "\n",
    "    # avg over batches\n",
    "    train_losses.append(np.array(batch_losses).mean(axis=0))\n",
    "\n",
    "    print(f'Epoch {epoch:03d} | Loss >> {train_losses[-1][0]:.4f}/ {train_losses[-1][1]:.4f}/ {train_losses[-1][2]:.4f}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}